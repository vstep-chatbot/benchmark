This repo is used to benchmark embedding models and Vietnamese Tokenizers

### Benchmark Tokenizers

> [bench_tokenizers.ipynb](bench_tokenizers.ipynb)

- Original source code: [Huy Bik's Blog](https://huybik.github.io/Word-Tokenizer-Benchmark/)
- Test dataset is from [Universal Dependencies Vietnamese](https://github.com/UniversalDependencies/UD_Vietnamese-VTB).

### Benchmark Embedding Models

> [bench_embeddings.ipynb](bench_embeddings.ipynb)

- Original source code: [Bá Ngọc](https://colab.research.google.com/drive/15MiLoNLUslKnOhE6BpluHqSaFXhksJTm?usp=sharing).
- Test dataset is from [anti-ai/ViSTS](https://huggingface.co/datasets/anti-ai/ViSTS), which is the Vietnamese version of the well-known [MTEB dataset](https://huggingface.co/mteb). Check out their embedding models leaderboard [here](https://huggingface.co/spaces/mteb/leaderboard).
